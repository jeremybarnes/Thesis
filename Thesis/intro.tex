% intro.tex
% Jeremy Barnes, 21/9/1999
% $Id$

\chapter{Introduction}
\label{chapter:intro}

The project undertaken was an investigation of a method of
overcoming a known problem (\emph{overfitting}) of a particular
machine learning algorithm (the \emph{Boosting} algorithm).  The
result is a series of machine learning algorithms called
\emph{$p$-boosting algorithms}.  These algorithms are developed,
analysed and tested in later chapters.

\subsection*{Part I: Background}

This introduction provides an overview of the rest of the thesis, and
covers the bigger picture, describing the field of machine learning
and its applications to practical problems.

The next three chapters rapidly narrow the focus.  Chapter
\ref{chapter:slt} describes the field of \emph{Statistical learning
theory} (SLT)\footnote{A table of acronyms is provided in the
preface.}, which provides much of the theoretical
foundation of (but by no means encompasses) the field of machine
learning.  Assumptions of \emph{binary problems} and
\emph{classification problems} further restrict the scope of the
investigation.

Chapter \ref{chapter:stumps} provides a description of, and proves
some properties of, a very simple learning algorithm called
\emph{decision stumps} which fits within the restricted scope imposed
by the first two chapters.  This learning algorithm is used as a basis
for the more powerful Boosting algorithms described later.

With the necessary background in place, the \emph{Boosting} algorithm
itself is the subject of chapter \ref{chapter:boosting}.  This
algorithm forms the starting point for the original work that is
considered in further chapters.  The \emph{problem} of overfitting in
boosting is investigated, as a prelude to the \emph{solutions}
investigated in the second part of the thesis. 


\subsection*{Part II: New work}

The key inventive step of the project is the use of a \emph{$p$-convex
hull} to reduce the problem of overfitting.  Chapter
\ref{chapter:pboosting} investigates the theoretical justification
behind this line of reasoning in some detail.  These abstract ideas
are then developed into concrete algorithms, and properties of these
algorithms are considered.

Chapter \ref{chapter:method} describes how these algorithms were
tested.  Chapter \ref{chapter:results} details the main results of the
project, and discusses their significance and relation to the theory.
A conclusion (chapter \ref{chapter:conclusion}) completes the thesis, 
evaulating the results obtained in the context of the project and in
the broader scope of the field of machine learning.  Suggestions of
avenues further enquiry which may prove fruitful are also made.

\section{The scheme of things}

This section provides an overview of the context of this project,
starting very broadly and rapidly focusing on the immediate
background. 


\subsection{Artificial intelligence}

The broadest possible subject area in which this work is contained is
often described as \emph{artificial intelligence}.  This field
essentially contains our efforts to make computers act in a similar
manner to humans, encompassing a large body of history, philosophy and
knowledge (see, for example \cite{Penrose89}).  We will ignore much
of this, and concentrate on efforts to make computers ``learn''.

Early work in this field (from the 1950s to the 1980s) was based on
the idea that intelligence can be emulated with a large set of rules.
The systems generated as a result, known as \emph{expert systems},
were huge databases of human-generated rules that were meant to
represent the complete knowledge of a human expert over a particular
problem domain.  These systems were reasonably successful at first,
but became unwieldy as the number of rules increased (a large amount
of effort is required to generate even the 1000 rules that were used
in large expert systems in 1980). 

The problem was more practical than theoretical: systems with large
numbers of rules can theoretically learn any learnable problem to a
desired accuracy; it is \emph{generating} the rules that is hard.  The
next step, obvious in hindsight, was to invent machines that could
generate their own rules; machines that could \emph{learn}.


\subsection{Machine learning}

Learning machines came in two flavours.  \emph{Supervised learners} are
shown examples of some kind of relationship, along with the ``right''
answers (generated from some form of supervisor) and attempt to learn a
relationship such that their answer always matches that of the
supervisor.  An example is trying to learn the likely outcome of a
court case based upon details of similar cases (the ``supervisor''
here is the information on the outcomes of cases on file).  All
algorithms discussed in this thesis are supervised algorithms.
\emph{Unsupervised algorithms} are given a set of data and asked to
learn a pattern in the data (for example, identifying interesting
clumps of stars from telescope images).


\subsection{Statistical learning theory}

Machine learning rests upon the theoretical foundation of statistical
learning theory (SLT).  It provides a body of knowledge that allows
bounds on the performance of learning algorithms to be generated%
\footnote{Much of this theory can be attributed to V.N.Vapnik
\cite{Vapnik98}.}.
Results from statistical learning theory enable us to be confident
that learning machines will learn in a manner that is close to optimal.

\subsection{Voting methods}

Boosting is an example of a \emph{voting method}, a relatively new
class of algorithm which operates in a bootstrap-like 
manner by combining many ``weak''%
\footnote{Strictly, the term ``weak'' is used in an informal manner
only; we call any non-voting method weak.  However, it is usually true
that these weak algorithms perform significantly worse than voting
methods.}
hypotheses to generate a composite ``strong'' hypothesis.  Their success
algorithms has been remarkable; as a result of these algorithms the
focus of machine learning research in recent years has shifted from
the classical algorithms (all of which are more or less equal when
boosted) to developments in voting methods.

These algorithms were initially observed to be immune to many of the
problems of overfitting.  Recent results have indicated that this is
unfortunately not the case.

\subsection{A real-world application}
\label{sec:churn example}

Consider a telephone company that is interested in predicting whether
its customers are likely to ``churn'' (change telephone companies) in
the near future.  Such a telephone company will have a detailed
database with customer statistics such as frequency of telephone
usage, number of service calls, etc.  This data can be used to train a
learning machine.   The resultant learning machine can then be used to
predict whether current customers are likely to churn (classify
customers into ``churn'' and ``not churn'' categories).  The company
can then target these likely customers with special offers or improved
service, thereby retaining their custom.

\section{Issues in machine learning}

Machine learning is a mathematically hard (ill-posed) problem, and
there are many issues involved.  A real-world example of many of these
problems%
\footnote{Part of machine learning folklore.}
concerns efforts by the US army to construct a learning machine to
detect tanks from photographs.  The training data was two sets of
photographs of terrain; one set including tanks and the other without.
Each set of  photographs was taken at a different time during the day.
When the learning machine was trained, it learned to detect
differences in the sun position rather than the presence of tanks!
Although the learning machine could classify the training data
correctly, its generalisation ability was poor.

Overfitting, simply put, is learning the specifics of a process too
well to be able to apply the knowledge to a more general problem.  In
the context of machine learning, overfitting occurs when the learning
machine adapts to peculiarities or noise in the input data, to the
detriment of generalisation ability.

Statistical learning theory gives us a theoretical reason for
overfitting, and also an insight into how it may be avoided.  In
particular, by limiting the complexity of the \emph{set} of hypotheses
that the learning machine may generate we can avoid overfitting (this
technique is known as \emph{capacity control}.


\section{Original work}

We consider one method of 

The original work of this project is motivated by observations of a
theoretical bound on overfitting; and in particular on a method of
reducing overfitting in the boosting algorithm.  This theory is first
developed into several practical algorithms; these algorithms are then
tested against the original AdaBoost algorithm and for compliance with
the theory behind them.





